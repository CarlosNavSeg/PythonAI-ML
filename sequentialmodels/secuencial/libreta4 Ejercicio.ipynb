{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Uso de callbacks\n","\n","En este ejercicio, implementaremos métodos de callbacks para detener el entrenamiento cuando se cumpla una métrica específica. Esta es una función útil, ya que permitirá no completar todas las épocas cuando se alcance este umbral. Por ejemplo, si configuramos 1000 épocas y la precisión deseada ya se alcanza en la época 200, el entrenamiento se detendrá automáticamente. Veamos cómo se implementa esto en las siguientes secciones."],"metadata":{"id":"uLCnbxhWrjXD"}},{"cell_type":"markdown","source":["## Cargamos y normalizamos el conjunto de datos MNIST de moda\n","\n","Al igual que en el ejercicio anterior, volveremos a utilizar el conjunto de datos Fashion MNIST.Recuerda que debemos ormalizar los valores de píxeles para ayudar a optimizar el entrenamiento."],"metadata":{"id":"AzcJ1enAruL2"}},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","from tensorflow import keras\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# Instanciamos el conjunto de datos\n","mnist = tf.keras.datasets.fashion_mnist\n","# Cargamos el dataset\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n","# Normalizamos los valores\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JGaDdEH0rvcf","outputId":"71b961fe-efb9-46b6-a36f-b738e1879314","executionInfo":{"status":"ok","timestamp":1700160037318,"user_tz":-60,"elapsed":5572,"user":{"displayName":"Carlos Navarro Segarra","userId":"08442718469004035589"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","29515/29515 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26421880/26421880 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","5148/5148 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4422102/4422102 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["train_images = train_images/255\n","test_images = test_images/255"],"metadata":{"id":"XcSReiLlbzlr","executionInfo":{"status":"ok","timestamp":1700160054381,"user_tz":-60,"elapsed":378,"user":{"displayName":"Carlos Navarro Segarra","userId":"08442718469004035589"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## Creamos una clase callbacks\n","\n","Puede crear un método callbacks definiendo una clase que herede la clase base [tf.keras.callbacks.Callback](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback). Desde allí, pudemos definir los métodos disponibles para establecer dónde se ejecutará la evaluación del método. Por ejemplo, a continuación, utilizará el método [on_epoch_end()](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback#on_epoch_end) para verificar el valor de la loss function al final de la época."],"metadata":{"id":"sbbyt0mKr2qq"}},{"cell_type":"code","source":["class myCallback(tf.keras.callbacks.Callback):\n","  def on_epoch_end(self, epoch, logs={}):\n","    if(logs.get('accuracy')>=0.8):\n","      print(\"La precision ha alcanzado el 80%, se cancela el entrenamiento\")\n","      self.model.stop_training = True\n","\n","callbacks = myCallback()\n","\n"],"metadata":{"id":"8Ltvh1CLr_8d","executionInfo":{"status":"ok","timestamp":1700160109753,"user_tz":-60,"elapsed":229,"user":{"displayName":"Carlos Navarro Segarra","userId":"08442718469004035589"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Definimos y compilamos el modelo\n","\n","A continuación, definiremos y compilaremos el modelo. La arquitectura será similar a la que se construyó en el laboratorio anterior. Luego, estableceremos el optimizador, la loss function y las métricas que usaremos para el entrenamiento."],"metadata":{"id":"j0lCEmWxsGPI"}},{"cell_type":"code","source":["model = tf.keras.models.Sequential([\n","    tf.keras.layers.Flatten(input_shape = (28,28)),\n","    tf.keras.layers.Dense(128, activation = \"relu\"),\n","    tf.keras.layers.Dense(10, activation=\"softmax\")\n","])\n","model.compile(loss=\"sparse_categorical_crossentropy\", optimizer = \"adam\", metrics=['accuracy'])"],"metadata":{"id":"g3O5kRs9sHX5","executionInfo":{"status":"ok","timestamp":1700160131474,"user_tz":-60,"elapsed":215,"user":{"displayName":"Carlos Navarro Segarra","userId":"08442718469004035589"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["### Entrenamos al modelo\n","\n","Ahora estamos listos para entrenar el modelo. Para configurar la devolución de llamada, simplemente configure el parámetro `callbacks` en la instancia `myCallback` que declaramos anteriormente."],"metadata":{"id":"0vtbMOxxsMvI"}},{"cell_type":"code","source":["model.fit(train_images, train_labels, epochs=12, callbacks=[callbacks])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7jAx-E4CsUUf","outputId":"2c7f3968-8b3e-4224-f133-8bf51b93e42d","executionInfo":{"status":"ok","timestamp":1700160206957,"user_tz":-60,"elapsed":9591,"user":{"displayName":"Carlos Navarro Segarra","userId":"08442718469004035589"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/12\n","1875/1875 [==============================] - ETA: 0s - loss: 0.3447 - accuracy: 0.8748La precision ha alcanzado el 80%, se cancela el entrenamiento\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.3447 - accuracy: 0.8748\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x78102f3f6e90>"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["Notarás que el entrenamiento no necesita completar las 10 épocas. Al evaluar el méotodo al final de la época, podemos verificar los parámetros de entrenamiento y comparar si cumplimos con el umbral establecido en la definición de la función. En este caso, simplemente se detendrá cuando la loss function caiga por debajo de `0.40` después de la época actual.\n","\n","*Desafío opcional: modifica el código para que el entrenamiento se detenga cuando la métrica de precisión supere el 60 %.*"],"metadata":{"id":"ahh9wiDUsYXR"}}]}